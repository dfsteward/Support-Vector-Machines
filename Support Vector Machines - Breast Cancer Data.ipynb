{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "The below Support Vector Machine Model is an assignment from an Udemy Machine Learning class \n",
    "\n",
    "https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/?utm_source=adwords&utm_medium=udemyads&utm_campaign=Python_v.PROF_la.EN_cc.US_ti.7380&utm_content=deal4584&utm_term=_._ag_78513466559_._ad_436603254913_._kw__._de_c_._dm__._pl__._ti_dsa-774930046209_._li_9030072_._pd__._&matchtype=b&gclid=Cj0KCQiA9P__BRC0ARIsAEZ6iriN81oGE4RLs6f0zCpoBHxAbJNchYTEvzNHU9QE-cNlYdKRtxqLnAAaAkiaEALw_wcB\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Using the Scikit-Learn built in breast cancer dataset (a copy of the UCI ML Breast Cancer Wisconsin (Diagnostic) datasets), determine wheather test cases are Malignant or Benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "\n",
    "* [Import Libraries](#import_libraries)\n",
    "* [Import Data](#import_data)\n",
    "* [Create DataFrame and Descriptive Metrics](#create_dataframe)\n",
    "* [Data Preprocessing; check for nulls](#data_preprocessing)\n",
    "* [Exploratory Data Analysis](#explore_data)\n",
    "* [Splitting the data into training and testing sets](#split_data)\n",
    "* [Create and Train the Model](#train_model)\n",
    "* [Predictions from our Model](#predict)\n",
    "* [Evaluation Metrics](#eval_metrics)\n",
    "* [Gridsearch](#grid_search)\n",
    "* [Predictions from Gridsearch Model](#gs_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import_libraries\"></a>\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import_data\"></a>\n",
    "## Import Data\n",
    "\n",
    "For this project we are using an Scikit-Learn built in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn dataset\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call load_breast_cancer and assign to variable\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "#view keys and explore/understand data\n",
    "print(cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view description of dataset\n",
    "#print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute definitions:\n",
    "- **radius** (mean of distances from center to points on the perimeter)\n",
    "- **texture** (standard deviation of gray-scale values)\n",
    "- **perimeter**\n",
    "- **area**\n",
    "- **smoothness** (local variation in radius lengths)\n",
    "- **compactness** (perimeter^2 / area - 1.0)\n",
    "- **concavity** (severity of concave portions of the contour)\n",
    "- **concave points** (number of concave portions of the contour)\n",
    "- **symmetry**\n",
    "- **fractal dimension** (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"create_dataframe\"></a>\n",
    "## Create DataFrame and Descriptive Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a feature dataframe\n",
    "df_feat = pd.DataFrame(data=cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a target class dataframe\n",
    "df_target= pd.DataFrame(data=cancer['target'],columns=['Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cancer\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data_preprocessing\"></a>\n",
    "## Data Preprocessing; check for nulls  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email                   0\n",
       "Address                 0\n",
       "Avatar                  0\n",
       "Avg. Session Length     0\n",
       "Time on App             0\n",
       "Time on Website         0\n",
       "Length of Membership    0\n",
       "Yearly Amount Spent     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"explore_data\"></a>\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the relationship between the feature attributes and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.displot(df['Yearly Amount Spent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a correlation matrix, round to 2 decimal places\n",
    "#correlation_matrix = customers.corr().round(2)\n",
    "#correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the correlation matrix as a heat map\n",
    "#sns.heatmap(data=correlation_matrix,annot=True)\n",
    "\n",
    "#sns.heatmap(data=df.corr().round(2),annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='Time on Website',y='Yearly Amount Spent',data=customers,kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='Time on App',y='Yearly Amount Spent',data=customers,kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='Time on App',y='Length of Membership',data=customers,kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lmplot(x='Length of Membership', y='Yearly Amount Spent', data=customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"split_data\"></a>\n",
    "## Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature and label datasets;\n",
    "\n",
    "For the feature dataset, create a new dataset with only the feature attributes you want; using pandas or numpy 'concatenate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label dataframe (Y)\n",
    "\n",
    "y = cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_state = 5, to tie out to 'towards data science' tutorial\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"train_model\"></a>\n",
    "## Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import support vector classifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit to training data\n",
    "\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"predict\"></a>\n",
    "## Predictions from our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to our Test data, then compare the predictions to the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in data the model hasn't seen before (feature data set of our test data)\n",
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"eval_metrics\"></a>\n",
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  10]\n",
      " [  3 102]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        66\n",
      "           1       0.91      0.97      0.94       105\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.93      0.91      0.92       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"grid_search\"></a>\n",
    "## Gridsearch\n",
    "\n",
    "Search for the optimal parameters for the model by performing a gridsearch (try out all possible combinations of parameters); also consider normalizing data as well\n",
    "\n",
    "**GridSearchCV (Cross Validation)**: takes a dictionary that describes the parameters (param_grid) that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested. \n",
    "\n",
    "GridSearchCV is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. Add refit=True (refit: Refit an estimator using the best found parameters on the whole dataset.)and choose verbose to whatever number you want, higher the number, the more verbose (verbose just means the text output describing the process).\n",
    "\n",
    "C & Gamma SVM parameter affect on Radial Basis Function (RBF) kernel: \n",
    "* C = controls the cost of misclassification on training data  \n",
    "   * Large C value = low bias (because you penalize the cost of misclassification), high variance  \n",
    "   * Smaller C value= higer bias, lower variance  \n",
    "* gamma = defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the *inverse of the radius of influence of samples* selected by the model as support vectors.  \n",
    "    * Large gamma value = higer bias, lower variance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate GridSearchCV with the model and parameters\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .......................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .......................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .......................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .......................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .......................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ......................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ......................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ......................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ......................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ......................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .....................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .....................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .....................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .....................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .....................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ....................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ....................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ....................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ....................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the estimator to your data\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the best parameters; best_params_  attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the best estimator in the best\\_estimator_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.0001)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"gs_predict\"></a>\n",
    "## Predictions from Gridsearch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from Model with Gridsearch parameters:\n",
      "\n",
      "\n",
      "[[ 59   7]\n",
      " [  4 101]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91        66\n",
      "           1       0.94      0.96      0.95       105\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.94      0.93      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Predictions from Model with Gridsearch parameters:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,grid_predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from Model with default parameters:\n",
      "\n",
      "\n",
      "[[ 56  10]\n",
      " [  3 102]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        66\n",
      "           1       0.91      0.97      0.94       105\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.93      0.91      0.92       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Predictions from Model with default parameters:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
